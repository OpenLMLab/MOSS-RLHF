# MOSS-RLHF

### *MOSS-RLHF & "Secrets of RLHF in Large Language Models Part I: PPO" <br>ðŸ‘‰ <a href="https://openlmlab.github.io/MOSS-RLHF/assets/paper/SecretsOfRLHFPart1.pdf" target="_blank">[Technical report]*</a>

<p align="center" width="100%">
<a href="https://openlmlab.github.io/MOSS-RLHF/assets/paper/SecretsOfRLHFPart1.pdf" target="_blank"><img src="./assets/img/moss.png" alt="MOSS" style="width: 50%; min-width: 300px; display: block; margin: auto;"></a>

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-brightgreen.svg)](./LICENSE)
[![Data License](https://img.shields.io/badge/Data%20License-CC%20BY--NC%204.0-blue.svg)](./DATA_LICENSE)
[![Model License](https://img.shields.io/badge/Model%20License-GNU%20AGPL%203.0-red.svg)](./MODEL_LICENSE)

This is the open-source code repository for the technical report: "Secrets of RLHF in Large Language Models Part I: PPO"

<img style="width: 90%; min-width: 500px; display: block; margin: auto; margin-bottom: 20px" alt="MOSS-RLHF" src="./assets/img/img1.jpg">


<img style="width: 90%; min-width: 500px; display: block; margin: auto; margin-bottom: 20px" alt="MOSS-RLHF" src="./assets/img/img2.jpg">


## Open-source List
- Two 7B reward model based on openChineseLlama and Llama-7B, respectively.
- Open source code for RL training in large language models.
- ...

## Getting Started

TODO, To be finalised before 15. July 2023

## Citation

```bibtex
@article{zheng2023secrets,
  title={Secrets of RLHF in Large Language Models Part II: PPO}, 
  author={Rui Zheng and Shihan Dou and Songyang Gao and Yuan Hua and Wei Shen and Binghai Wang and Yan Liu and Senjie Jin and Qin Liu and Yuhao Zhou and Limao Xiong and Lu Chen and Zhiheng Xi and Nuo Xu and Wenbin Lai and Minghao Zhu and Cheng Chang and Zhangyue Yin and Rongxiang Weng and Wensen Cheng and Haoran Huang and Tianxiang Sun and Hang Yan and Tao Gui and Qi Zhang and Xipeng Qiu and Xuanjing Huang},
  year={2023}
}
```
